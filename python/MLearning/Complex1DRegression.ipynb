{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import matplotlib.animation as animation\n",
    "import glob, re, os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# Don't use cuda with keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use('default')\n",
    "plt.style.use(['science', 'high-vis', 'grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, ax):\n",
    "    \"\"\" Plot the loss function. \"\"\"\n",
    "    ax.plot(history.history['loss'], label='loss')\n",
    "    ax.plot(history.history['val_loss'], label='val_loss')\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_dir = \"../../build/DATASET_COMPLEX_SPAD/\"\n",
    "list_of_files = glob.glob(dataset_path_dir + \"*.csv\")\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "dataset_path = latest_file\n",
    "print(\"Dataset path: \", dataset_path)\n",
    "df = pd.read_csv(dataset_path, sep=\",\", header=0)\n",
    "\n",
    "idx_BV = df.columns.get_loc(\"BreakdownVoltage\")\n",
    "idxBrP = idx_BV + 1\n",
    "idxDW = idx_BV + 2\n",
    "idxDoping = np.arange(1, idx_BV, 1)\n",
    "print(idxDoping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values\n",
    "df = df.dropna()\n",
    "df.tail()\n",
    "\n",
    "# The columns in idxDoping must be log10 transformed and the sign kept\n",
    "df.iloc[:, idxDoping] =np.log10(df.iloc[:, idxDoping])\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network regression to learn BV from Total Length, Donor Length, Donor Level and Acceptor level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network regression to learn BV from Total Length, Donor Length, Donor Level and Acceptor level.\n",
    "# We will use the keras/TensorFlow library to build the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_dataset = df.sample(frac=0.5, random_state=0)\n",
    "test_dataset = df.drop(train_dataset.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data\n",
    "pp = sns.pairplot(train_dataset[[\"TotalLength\", \"BreakdownVoltage\", \"BreakdownProbability\", \"DepletionWidth\"]], diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.scatter(train_dataset[\"BreakdownVoltage\"], train_dataset[\"DepletionWidth\"], s=2, marker='.', alpha=0.65, edgecolors='k', linewidths=0.1)\n",
    "axs.set_xlabel(\"Breakdown Voltage (V)\")\n",
    "axs.set_ylabel(\"Depletion Width ($\\mu$m)\")\n",
    "fig.savefig(\"BreakdownVoltage_vs_DepletionWidth_MC_Sampling.png\", dpi=300)\n",
    "fig.savefig(\"BreakdownVoltage_vs_DepletionWidth_MC_Sampling.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.scatter(train_dataset[\"BreakdownVoltage\"], train_dataset[\"BreakdownProbability\"], s=2, marker='.', alpha=0.65, edgecolors='k', linewidths=0.1)\n",
    "axs.set_xlabel(\"Breakdown Voltage (V)\")\n",
    "axs.set_ylabel(\"Breakdown Probability\")\n",
    "axs.set_ylim(0, 1)\n",
    "fig.savefig(\"BreakdownVoltage_vs_BreakdownProbability_MC_Sampling.png\", dpi=300)\n",
    "fig.savefig(\"BreakdownVoltage_vs_BreakdownProbability_MC_Sampling.pdf\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "Labels_Features = [\"BreakdownVoltage\", \"BreakdownProbability\", \"DepletionWidth\"]\n",
    "\n",
    "train_labels = train_features.pop(Labels_Features[0])\n",
    "test_labels = test_features.pop(Labels_Features[0])\n",
    "\n",
    "train_labels = train_features.pop(Labels_Features[1])\n",
    "test_labels = test_features.pop(Labels_Features[1])\n",
    "\n",
    "train_labels = train_features.pop(Labels_Features[2])\n",
    "test_labels = test_features.pop(Labels_Features[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(normalizer.mean.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try with a simple linear model\n",
    "linear_model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "linear_model.summary()\n",
    "\n",
    "linear_model.predict(train_features[:10])\n",
    "linear_model.layers[1].kernel\n",
    "\n",
    "linear_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error')\n",
    "\n",
    "history = linear_model.fit(\n",
    "    train_features,\n",
    "    train_labels_BV,\n",
    "    epochs=200,\n",
    "    # suppress logging\n",
    "    verbose=1,\n",
    "    # Calculate validation results on 20% of the training data\n",
    "    validation_split = 0.2)\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_loss(history, ax)\n",
    "ax.set_ylim(bottom=0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with a deep neural network (Input size is 201)\n",
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(2048, activation='relu'),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'), \n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "dnn_model_BV = build_and_compile_model(normalizer)\n",
    "dnn_model_BV.summary()\n",
    "\n",
    "history_BV = dnn_model_BV.fit(\n",
    "    train_features, train_labels_BV,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "plot_loss(history_BV, ax)\n",
    "ax.set_ylim(bottom=-2.0)\n",
    "# Inset zoom\n",
    "# axins = ax.inset_axes([0.4, 0.4, 0.5, 0.5])\n",
    "# plot_loss(history_BV, axins)\n",
    "# axins.set_xlim(history_BV.epoch[-1]-50, history_BV.epoch[-1])\n",
    "# axins.set_ylim(0.0, 2.0)\n",
    "# ax.indicate_inset_zoom(axins, edgecolor=\"k\", alpha=0.95)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Error [BV]')\n",
    "\n",
    "fig.legend(loc='lower center', ncol=2, bbox_to_anchor=(0.5, -0.07), frameon=True, fancybox=True, shadow=False)\n",
    "fig.tight_layout()\n",
    "fig.savefig('BV_loss.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_predictions_BV = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.scatter(test_labels_BV, test_predictions_BV, s=1)\n",
    "ax.set_xlabel('True Values [BV]')\n",
    "ax.set_ylabel('Predictions [BV]')\n",
    "ax.set_aspect('equal')\n",
    "minmax_x = np.array([0, 1.1*np.max(test_labels_BV)])\n",
    "ax.plot(minmax_x, minmax_x, color='k', linestyle='--', label='y=x')\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_BrP = dnn_model.fit(\n",
    "    train_features, train_labels_BrP,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "plot_loss(history_BrP, ax)\n",
    "ax.set_ylim(bottom=-0.10, top=2.0)\n",
    "# Inset zoom\n",
    "axins = ax.inset_axes([0.4, 0.4, 0.5, 0.5])\n",
    "plot_loss(history_BrP, axins)\n",
    "axins.set_xlim(history_BrP.epoch[-1]-50, history_BrP.epoch[-1])\n",
    "axins.set_ylim(0.0, 0.10)\n",
    "ax.indicate_inset_zoom(axins, edgecolor=\"k\", alpha=0.95)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Error [BrP]')\n",
    "\n",
    "fig.legend(loc='lower center', ncol=2, bbox_to_anchor=(0.5, -0.07), frameon=True, fancybox=True, shadow=False)\n",
    "fig.tight_layout()\n",
    "fig.savefig('BV_loss.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_predictions_BrP = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.scatter(test_labels_BrP, test_predictions_BrP, s=1)\n",
    "ax.set_xlabel('True Values [BrP]')\n",
    "ax.set_ylabel('Predictions [BrP]')\n",
    "ax.set_aspect('equal')\n",
    "minmax_x = np.array([0, 1.1*np.max(test_labels_BrP)])\n",
    "ax.plot(minmax_x, minmax_x, color='k', linestyle='--', label='y=x')\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_DW = dnn_model.fit(\n",
    "    train_features, train_labels_DW,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "plot_loss(history_DW, ax)\n",
    "ax.set_ylim(bottom=-0.10, top=1.0)\n",
    "# Inset zoom\n",
    "axins = ax.inset_axes([0.4, 0.4, 0.5, 0.5])\n",
    "plot_loss(history_DW, axins)\n",
    "axins.set_xlim(history_DW.epoch[-1]-50, history_DW.epoch[-1])\n",
    "axins.set_ylim(0.0, 0.1)\n",
    "ax.indicate_inset_zoom(axins, edgecolor=\"k\", alpha=0.95)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Error [DW]')\n",
    "\n",
    "fig.legend(loc='lower center', ncol=2, bbox_to_anchor=(0.5, -0.07), frameon=True, fancybox=True, shadow=False)\n",
    "fig.tight_layout()\n",
    "fig.savefig('BV_loss.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_predictions_DW = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.scatter(test_labels_DW, test_predictions_DW, s=1)\n",
    "ax.set_xlabel('True Values [DW]')\n",
    "ax.set_ylabel('Predictions [DW]')\n",
    "ax.set_aspect('equal')\n",
    "minmax_x = np.array([0, 1.1*np.max(test_labels_DW)])\n",
    "ax.plot(minmax_x, minmax_x, color='k', linestyle='--', label='y=x')\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
