{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import matplotlib.animation as animation\n",
    "import glob, re, os\n",
    "import subprocess\n",
    "\n",
    "from smt.applications.mixed_integer import (\n",
    "    MixedIntegerContext,\n",
    "    FLOAT,\n",
    "    ENUM,\n",
    "    ORD,\n",
    ")\n",
    "\n",
    "import scipy.linalg as lng\n",
    "\n",
    "from smt.applications import EGO\n",
    "from smt.surrogate_models import KRG\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use('default')\n",
    "plt.style.use(['science', 'high-vis', 'grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_COST_CPP = \"/work/utox/users/helleboid_work_utox/OptiDopi/build/apps/spad_cost_function\"\n",
    "RES_FILE = \"RES/res_cost_func.csv\"\n",
    "\n",
    "os.makedirs(\"RES/\", exist_ok=True)\n",
    "\n",
    "def function_test_1d(length_intrinsic):\n",
    "    doping_acceptor = 17.0\n",
    "    subprocess.run([PATH_COST_CPP, f\"{length_intrinsic}\", f\"{doping_acceptor}\", RES_FILE])\n",
    "    length_intrinsic,doping_acceptor, BV,BrP,DW,BV_cost,BP_cost,DW_cost,total_cost = np.loadtxt(RES_FILE, delimiter=\",\", unpack=True)\n",
    "    print(f)\n",
    "    return total_cost\n",
    "\n",
    "def function_test_2d(PARAMS):\n",
    "    #print(PARAMS)\n",
    "    Y = []\n",
    "    for idx in range(len(PARAMS)):\n",
    "        length_intrinsic = PARAMS[idx,0]\n",
    "        #print(f'{length_intrinsic=}')\n",
    "        log_doping_acceptor =  PARAMS[idx,1]\n",
    "        subprocess.run([PATH_COST_CPP, f\"{length_intrinsic}\", f\"{log_doping_acceptor}\", RES_FILE])\n",
    "        length_intrinsic,doping_acceptor, BV,BrP,DW,BV_cost,BP_cost,DW_cost,total_cost = np.loadtxt(RES_FILE, delimiter=\",\", unpack=True)\n",
    "        Y.append(total_cost)\n",
    "        print(f\"Total cost: {total_cost}\")\n",
    "    return np.array(Y)\n",
    "\n",
    "vfunc = np.vectorize(function_test_1d)\n",
    "\n",
    "vfunc2d = np.vectorize(function_test_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 2055.365\n",
      "Total cost: 852.2339\n",
      "Total cost: 10000000000.0\n",
      "Total cost: -45.5323\n",
      "Total cost: 1518.021\n"
     ]
    }
   ],
   "source": [
    "min_length_intrinsic = 0.0\n",
    "max_length_intrinsic = 1.0\n",
    "min_log_acceptor = 16.5\n",
    "max_log_acceptor = 19.0\n",
    "\n",
    "\n",
    "n_iter = 1000\n",
    "xtypes = [FLOAT, FLOAT]\n",
    "#mixint = MixedIntegerContext(xtypes, xlimits)\n",
    "xlimits = np.array([[min_length_intrinsic, max_length_intrinsic], [min_log_acceptor, max_log_acceptor]])\n",
    "\n",
    "qEI = \"KB\"\n",
    "sm = KRG(print_global=False)\n",
    "mixint = MixedIntegerContext(xtypes, xlimits)\n",
    "n_doe = 5\n",
    "sampling = LHS(xlimits=xlimits)\n",
    "xdoe = sampling(n_doe)\n",
    "ydoe = function_test_2d(xdoe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 2055.365\n",
      "Total cost: 852.2339\n",
      "Total cost: 10000000000.0\n",
      "Total cost: -45.5323\n",
      "Total cost: 1518.021\n",
      "Total cost: 752.4807\n",
      "Total cost: 310.5109\n",
      "Total cost: 2344.167\n",
      "Total cost: 510.6477\n",
      "Total cost: 1152.474\n",
      "Total cost: 1412.58\n",
      "Total cost: 1531.083\n",
      "Total cost: 1525.807\n",
      "Total cost: 1191.893\n",
      "Total cost: 2066.726\n",
      "Total cost: 2270.89\n",
      "Total cost: 394.4212\n",
      "Total cost: 2812.146\n",
      "Total cost: 2004.691\n",
      "Total cost: 40.35439\n",
      "Total cost: 3976.141\n",
      "Total cost: 347.0906\n",
      "Total cost: -30.90319\n",
      "Total cost: 3702.385\n",
      "Total cost: 78.79398\n",
      "Total cost: 637.0199\n",
      "Total cost: 896.4461\n",
      "Total cost: 903.5274\n",
      "Total cost: 21.16015\n",
      "Total cost: 397.4981\n",
      "Total cost: 2471.053\n",
      "Total cost: 60.266\n",
      "Total cost: 188.3946\n",
      "Total cost: 188.3946\n",
      "Total cost: 172.7131\n",
      "Total cost: 1327.968\n",
      "Total cost: 31.55685\n",
      "Total cost: 1527.364\n",
      "Total cost: 1527.364\n",
      "Total cost: 787.6776\n",
      "Total cost: 1511.097\n",
      "Total cost: 2875.247\n",
      "Total cost: -39.1144\n",
      "Total cost: 1102.752\n",
      "Total cost: 790.3874\n",
      "Total cost: 1906.942\n",
      "Total cost: -59.62506\n",
      "Total cost: 2056.141\n",
      "Total cost: 1049.336\n",
      "Total cost: 450.323\n",
      "Total cost: 615.0699\n",
      "Total cost: 1528.693\n",
      "Total cost: 90.99624\n",
      "Total cost: 5.360101\n",
      "Total cost: 1938.96\n",
      "Total cost: 326.2515\n",
      "Total cost: -8.500051\n",
      "Total cost: 248.8351\n",
      "Total cost: 1330.702\n",
      "Total cost: 983.779\n",
      "Total cost: 1229.492\n",
      "Total cost: 714.1731\n",
      "Total cost: 367.2257\n",
      "Total cost: 527.0297\n",
      "Total cost: 263.4045\n",
      "Total cost: 1286.984\n",
      "Total cost: 852.2807\n",
      "Total cost: 576.0924\n",
      "Total cost: 67.28681\n",
      "Total cost: 467.4171\n",
      "Total cost: 143.6265\n",
      "Total cost: 102.9296\n",
      "Total cost: 4919.637\n",
      "Total cost: 250.4979\n",
      "Total cost: 469.7379\n",
      "Total cost: 1893.517\n",
      "Total cost: -9.219969\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 112.5463\n",
      "Total cost: 50.25003\n",
      "Total cost: 50.25002\n",
      "Total cost: 1623.011\n",
      "Total cost: 1623.011\n",
      "Total cost: -56.83158\n",
      "Total cost: 1531.431\n",
      "Total cost: 1050.424\n",
      "Total cost: 1416.123\n",
      "Total cost: 2374.769\n",
      "Total cost: 2896.157\n",
      "Total cost: 36.51732\n",
      "Total cost: 36.51732\n",
      "Total cost: -72.02728\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 1441.606\n",
      "Total cost: 1441.606\n",
      "Total cost: 1441.606\n",
      "Total cost: 1441.606\n",
      "Total cost: 1441.606\n",
      "Total cost: 1624.888\n",
      "Total cost: 1624.888\n",
      "Total cost: 2312.133\n",
      "Total cost: -36.53044\n",
      "Total cost: 136.967\n",
      "Total cost: 1420.039\n",
      "Total cost: -8.190616\n",
      "Total cost: 2005.107\n",
      "Total cost: 61.95095\n",
      "Total cost: 121.8299\n",
      "Total cost: 328.7731\n",
      "Total cost: 1798.334\n",
      "Total cost: 984.0597\n",
      "Total cost: 1629.304\n",
      "Total cost: 264.3301\n",
      "Total cost: 3309.994\n",
      "Total cost: 48.88121\n",
      "Total cost: 1362.95\n",
      "Total cost: 26.52348\n",
      "Total cost: 424.794\n",
      "Total cost: 169.351\n",
      "Total cost: 1192.418\n",
      "Total cost: 469.5548\n",
      "Total cost: 278.4473\n",
      "Total cost: -1.189433\n",
      "Total cost: 5424.102\n",
      "Total cost: 20.91056\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 896.5023\n",
      "Total cost: 1411.193\n",
      "Total cost: 1404.248\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 1430.285\n",
      "Total cost: 656.5793\n",
      "Total cost: 1056.081\n",
      "Total cost: 244.0774\n",
      "Total cost: 702.2237\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 323.7067\n",
      "Total cost: 843.9566\n",
      "Total cost: 739.2262\n",
      "Total cost: 38.65264\n",
      "Total cost: 1419.421\n",
      "Total cost: 207.9403\n",
      "Total cost: 658.1815\n",
      "Total cost: 658.1815\n",
      "Total cost: -8.327356\n",
      "Total cost: 716.6093\n",
      "Total cost: 142.5119\n",
      "Total cost: 1051.391\n",
      "Total cost: 1522.008\n",
      "Total cost: 2225.909\n",
      "Total cost: 1719.48\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 48.55738\n",
      "Total cost: 789.4988\n",
      "Total cost: 2348.664\n",
      "Total cost: 145.9228\n",
      "Total cost: 972.1837\n",
      "Total cost: 1613.259\n",
      "Total cost: 1015.214\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 296.4231\n",
      "Total cost: -14.06088\n",
      "Total cost: 649.9429\n",
      "Total cost: 987.6379\n",
      "Total cost: 1512.127\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 1.952172\n",
      "Total cost: 1421.34\n",
      "Total cost: 1421.34\n",
      "Total cost: 1421.34\n",
      "Total cost: 1421.34\n",
      "Total cost: 1421.34\n",
      "Total cost: 753.3477\n",
      "Total cost: 1305.882\n",
      "Total cost: 1305.882\n",
      "Total cost: 1213.932\n",
      "Total cost: 1561.668\n",
      "Total cost: 752.7089\n",
      "Total cost: 752.7089\n",
      "Total cost: 2373.56\n",
      "Total cost: 2275.508\n",
      "Total cost: 1718.35\n",
      "Total cost: 240.1152\n",
      "Total cost: 49.01924\n",
      "Total cost: 861.1225\n",
      "Total cost: 1415.075\n",
      "Total cost: 1415.075\n",
      "Total cost: 4.176386\n",
      "Total cost: 4.176384\n",
      "Total cost: 49.98402\n",
      "Total cost: -7.938311\n",
      "Total cost: 10000000000.0\n",
      "Total cost: 1241.661\n",
      "Total cost: 1410.378\n",
      "Total cost: 1410.378\n",
      "Total cost: 1007.571\n",
      "Total cost: 231.7692\n",
      "Total cost: 31.84562\n",
      "Total cost: 2275.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hellebor/my_utox/anaconda3/lib/python3.8/site-packages/smt/surrogate_models/krg_based.py:211: UserWarning: Warning: multiple x input features have the same value (at least same row twice).\n",
      "  warnings.warn(\"Warning: multiple x input features have the same value (at least same row twice).\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 169.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hellebor/my_utox/anaconda3/lib/python3.8/site-packages/smt/surrogate_models/krg_based.py:211: UserWarning: Warning: multiple x input features have the same value (at least same row twice).\n",
      "  warnings.warn(\"Warning: multiple x input features have the same value (at least same row twice).\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 737.5495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hellebor/my_utox/anaconda3/lib/python3.8/site-packages/smt/surrogate_models/krg_based.py:211: UserWarning: Warning: multiple x input features have the same value (at least same row twice).\n",
      "  warnings.warn(\"Warning: multiple x input features have the same value (at least same row twice).\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 536.4288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hellebor/my_utox/anaconda3/lib/python3.8/site-packages/smt/surrogate_models/krg_based.py:211: UserWarning: Warning: multiple x input features have the same value (at least same row twice).\n",
      "  warnings.warn(\"Warning: multiple x input features have the same value (at least same row twice).\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 536.4288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hellebor/my_utox/anaconda3/lib/python3.8/site-packages/smt/surrogate_models/krg_based.py:211: UserWarning: Warning: multiple x input features have the same value (at least same row twice).\n",
      "  warnings.warn(\"Warning: multiple x input features have the same value (at least same row twice).\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: -56.80642\n"
     ]
    }
   ],
   "source": [
    "criterion = \"SBO\"  #'EI' or 'SBO' or 'LCB'\n",
    "ego = EGO(n_iter=n_iter, criterion=criterion, xdoe=xdoe, xlimits=xlimits, xtypes=xtypes, qEI=qEI,\n",
    "          enable_tunneling=True)\n",
    "x_opt, y_opt, _, x_data, y_data = ego.optimize(fun=function_test_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum in x={} with f(x)={:.1f}\".format(x_opt, float(y_opt)))\n",
    "print(\"Minimum in typed x={}\".format(ego.mixint.cast_to_mixed_integer(x_opt)))\n",
    "\n",
    "min_ref = -15\n",
    "mini = np.zeros(n_iter)\n",
    "for k in range(n_iter):\n",
    "    mini[k] = np.log(np.abs(np.min(y_data[0 : k + n_doe - 1]) - min_ref))\n",
    "x_plot = np.linspace(1, n_iter + 0.5, n_iter)\n",
    "u = max(np.floor(max(mini)) + 1, -100)\n",
    "l = max(np.floor(min(mini)) - 0.2, -10)\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "axes.plot(x_plot, mini, color=\"r\")\n",
    "axes.set_ylim([l, u])\n",
    "plt.title(\"minimum convergence plot\", loc=\"center\")\n",
    "plt.xlabel(\"number of iterations\")\n",
    "plt.ylabel(\"log of the difference w.r.t the best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a45f6588c146a88407196641022ea045aa8d9112f76c45200dd5c3141264dd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
